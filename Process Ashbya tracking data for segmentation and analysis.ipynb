{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "# from ipywidgets import interact\n",
    "# import ipywidgets as widgets\n",
    "# import traitlets\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# from IPython.display import display, HTML\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from cStringIO import StringIO\n",
    "import pims\n",
    "from pims import ND2_Reader\n",
    "#from scipy.ndimage.morphology import grey_dilation\n",
    "# import PIL\n",
    "# from PIL import Image\n",
    "# from PIL.ImageSequence import Iterator\n",
    "import pandas as pd\n",
    "from scipy.io import savemat, loadmat\n",
    "from pandas import json\n",
    "\n",
    "\n",
    "import tifffile\n",
    "# import NetTracker\n",
    "# from NetTracker import TrackingData as TD\n",
    "# from vidUtils import *\n",
    "# from batchUtils import getVidFiles\n",
    "\n",
    "# import MCMClinker\n",
    "# from MCMClinker import DiffusionFilter as MCMC\n",
    "\n",
    "\n",
    "from datatank_py.DTDataFile import DTDataFile\n",
    "from datatank_py.DTProgress import DTProgress\n",
    "from datatank_py.DTSeries import DTSeriesGroup\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "def getFiles(path, kind='tif'):\n",
    "    kind = '.'+kind\n",
    "    fn = len(kind)\n",
    "    filenames = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            if f[-fn:] == kind:\n",
    "                filenames.append(os.path.join(root, f[:-fn]))\n",
    "    print('Total number of {0} files: '.format(kind[1:]), len(filenames))\n",
    "    return filenames \n",
    "class Make_obj:\n",
    "    def textureLine(self, d):\n",
    "        out = '{0} '.format('vt')\n",
    "        for dn in d:\n",
    "            out += '{0:1.6g} '.format(dn)\n",
    "        return out[:-1] + '\\n'\n",
    "    def normalsLine(self, d):\n",
    "        out = '{0} '.format('vn')\n",
    "        for dn in d:\n",
    "            out += '{0} '.format(dn)\n",
    "        return out[:-1] + '\\n'\n",
    "    def vertexLine(self, d):\n",
    "        out = 'v '\n",
    "        for dn in d:\n",
    "            out += '{0} '.format(dn)\n",
    "        return out[:-1] + '\\n'\n",
    "    def faceLine(self, d):\n",
    "        out = 'f '\n",
    "        for dn in d:\n",
    "            out += '{0}/{0}/{0} '.format(dn)\n",
    "        return out[:-1] + '\\n'\n",
    "    def __call__(self, points, faces=[], normals=[], values=[], objectLabel=1):\n",
    "        #out = 'o {0}\\n'.format(objectLabel)\n",
    "        out = ''\n",
    "        assert array(faces).size == 0 or array(faces).shape[1] == 3\n",
    "        assert array(points).shape[1] == 3\n",
    "        if 0 in faces:\n",
    "            faces += 1\n",
    "        for p in points:\n",
    "            out += self.vertexLine(p)\n",
    "        for n in normals:\n",
    "            out += self.normalsLine(n)\n",
    "        for v in values:\n",
    "            out += self.textureLine((v, 0, 0))\n",
    "        for face in faces:\n",
    "            out += self.faceLine(face)\n",
    "        return out\n",
    "path = '/Users/jaynewby/Dropbox/Gladfelter/'\n",
    "# savedir = 'GEMS-Whi3dpQ-june7'\n",
    "# savedir = 'GEMS-june11'\n",
    "savedir = 'GEMS-whi3tom'\n",
    "# savedir = 'GEMS-nuclei-june18'\n",
    "# savedir = 'GEMS-wbs'\n",
    "savePath = os.path.join(path, savedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save GEMS json data into directory of CSV files, folders with DataTank placeholders, and video metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CloudBasePath = 'gs://pipeline-proc'\n",
    "# tset = 'Wed Jun  6 20_26_16 2018--nd2.json'\n",
    "# tset = 'Wed Jun  6 21_50_38 2018--nd2.json'\n",
    "# tset = 'Thu Jun  7 14_00_59 2018--nd2.txt'\n",
    "tset = 'trackingData.txt'\n",
    "jsonfn = os.path.join(savePath, tset)\n",
    "with open(jsonfn, 'r') as jfile:\n",
    "    for line in jfile:\n",
    "        data = json.loads(line)\n",
    "        fn = data.keys()[0]\n",
    "        vdata = data[fn]\n",
    "        _, nameWithExt = os.path.split(fn)\n",
    "        name, ext = os.path.splitext(nameWithExt)\n",
    "        print(os.path.join(savePath, name))\n",
    "\n",
    "        if not os.path.isdir(savePath):\n",
    "            os.makedirs(savePath)\n",
    "\n",
    "        pdata = vdata['particleSet']\n",
    "        x, y, z = pdata['x'], pdata['y'], pdata['z']\n",
    "        t, p, r = pdata['t'], pdata['p'], pdata['r']\n",
    "        data = array([x, y, z, t, p, r])\n",
    "        df = pd.DataFrame(data.T, columns=['x', 'y', 'z', 't', 'p', 'r'])\\\n",
    "                .astype({'t': 'uint16'})\n",
    "\n",
    "        df.to_csv(os.path.join(savePath, name + ' (localizations).csv'))\n",
    "\n",
    "        ldata = vdata['tracks']\n",
    "        Uparticles = sort(array([int(v) for v in ldata.keys()], 'int'))\n",
    "        t, x, y, z, p, r = [], [], [], [], [], []\n",
    "        particle = []\n",
    "        for pn in Uparticles:\n",
    "            f = ldata[str(pn)]\n",
    "            x.extend(f['x'])\n",
    "            y.extend(f['y'])\n",
    "            z.extend(f['z'])\n",
    "            p.extend(f['p'])\n",
    "            r.extend(f['r'])\n",
    "            t.extend(f['t'])\n",
    "            particle.extend(pn*ones(len(f['x']), 'int'))\n",
    "        data = array([particle, t, x, y, z, p, r])\n",
    "        df = pd.DataFrame(\n",
    "                data.T, \n",
    "                columns=['particle', 'frame', 'x', 'y', 'z', 'p', 'r'])\\\n",
    "                .astype({'particle': 'int', 'frame': 'int'})\\\n",
    "                .sort_values(['particle', 'frame'], axis=0)\n",
    "        df.to_csv(os.path.join(savePath, name + ' (tracks).csv'))\n",
    "        #########################\n",
    "        md = vdata['metadata']\n",
    "        #c = md['conversions']\n",
    "        md['dt'] = 1.0\n",
    "        NF, Ny, Nx, Nz = md['vidShape']\n",
    "        print(NF, Ny, Nx, Nz)\n",
    "        outdict = {'Seq_NF': array([u'Real Number'], dtype='<U11'),\n",
    "                   'Seq_Nx': array([u'Real Number'], dtype='<U11'),\n",
    "                   'Seq_Ny': array([u'Real Number'], dtype='<U11'),\n",
    "                   'Seq_Nz': array([u'Real Number'], dtype='<U11'),\n",
    "                   'Seq_dxy': array([u'Real Number'], dtype='<U11'),\n",
    "                   'Seq_dz': array([u'Real Number'], dtype='<U11'),\n",
    "                   'Seq_dt': array([u'Real Number'], dtype='<U11'),\n",
    "                   'NF': array([[NF]], dtype='int32'),\n",
    "                   'Nx': array([[Nx]], dtype='int32'),\n",
    "                   'Ny': array([[Ny]], dtype='int32'),\n",
    "                   'Nz': array([[Nz]], dtype='int32'),\n",
    "                   'dxy': array([[md['dxy']]], dtype='float32'),\n",
    "                   'dz': array([[md['dz']]], dtype='float32'),\n",
    "                   'dt': array([[md['dt']]], dtype='float32')}\n",
    "        #savemat(os.path.join(savePath, name + '-videoMetaData.mat'), outdict, format='4')\n",
    "        placeHolderPath = os.path.join(savePath, name)\n",
    "        if not os.path.isdir(placeHolderPath):\n",
    "            os.mkdir(placeHolderPath)\n",
    "        for t in arange(NF):\n",
    "            with open(os.path.join(placeHolderPath, '{0}.dtph'.format(t)), 'w') as file:\n",
    "                file.write('nothing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get metadata from the Gladfelter lab drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pims\n",
    "GladPath = '/Volumes/GladfelterLab/Erin/GEMS/jay/'\n",
    "folder = 'WBS GEMS'\n",
    "assert len(folder) > 0\n",
    "GladPath += folder\n",
    "if not os.path.isdir(savePath):\n",
    "    os.makedirs(savePath)\n",
    "files = getFiles(GladPath, kind='nd2')\n",
    "for fn in files:\n",
    "    _, name = os.path.split(fn)\n",
    "    with pims.open(fn+'.nd2') as frames:\n",
    "        outDict = {}\n",
    "        print(name)\n",
    "        mdVid = frames.metadata\n",
    "        Nx = frames.sizes['x']\n",
    "        Ny = frames.sizes['y']\n",
    "        Nz = frames.sizes['z']\n",
    "        try:\n",
    "            NF = frames.sizes['t']\n",
    "        except:\n",
    "            continue\n",
    "        print(NF, Ny, Nx, Nz)\n",
    "        md0 = frames[0].metadata\n",
    "        md1 = frames[1].metadata\n",
    "        dt = mean(array(md1['t_ms']) - array(md0['t_ms']))/1000.\n",
    "        dxy = frames.calibration\n",
    "        dz = frames.calibrationZ\n",
    "        zscale = frames.calibrationZ/frames.calibration\n",
    "        outdict = {\n",
    "            'Seq_NF': array([u'Real Number'], dtype='<U11'),\n",
    "            'Seq_Nx': array([u'Real Number'], dtype='<U11'),\n",
    "            'Seq_Ny': array([u'Real Number'], dtype='<U11'),\n",
    "            'Seq_Nz': array([u'Real Number'], dtype='<U11'),\n",
    "            'Seq_dxy': array([u'Real Number'], dtype='<U11'),\n",
    "            'Seq_dz': array([u'Real Number'], dtype='<U11'),\n",
    "            'Seq_dt': array([u'Real Number'], dtype='<U11'),\n",
    "            'NF': array([[NF]], dtype='int32'),\n",
    "            'Nx': array([[Nx]], dtype='int32'),\n",
    "            'Ny': array([[Ny]], dtype='int32'),\n",
    "            'Nz': array([[Nz]], dtype='int32'),\n",
    "            'dxy': array([[dxy]], dtype='float32'),\n",
    "            'dz': array([[dz]], dtype='float32'),\n",
    "            'dt': array([[dt]], dtype='float32')}\n",
    "        savemat(\n",
    "            os.path.join(\n",
    "                savePath, \n",
    "                name + '-videoMetaData.mat'), \n",
    "            outdict, \n",
    "            format='4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save points in obj file for hand segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objSaveDir = 'HyphaDensityProject/{0} (points for segmentation)'.format(savedir)\n",
    "files = [fn for fn in getFiles(savePath, kind='csv') if '(tracks)' in fn]\n",
    "if not os.path.isdir(objSaveDir):\n",
    "    os.mkdir(objSaveDir)\n",
    "for fn in files:\n",
    "    _, name = os.path.split(fn)\n",
    "    data = pd.read_csv(fn + '.csv')\n",
    "    points = array(data[['x', 'y', 'z']])\n",
    "    with open(os.path.join(objSaveDir, name + '.obj'), 'w+b') as ofile:\n",
    "        print(ofile.name)\n",
    "        ofile.write(Make_obj()(points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert segmented txt files to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ObjPath = '/Users/jaynewby/Dropbox/Gladfelter/HyphaDensityProject/'\n",
    "ObjPath += savedir + ' (points for segmentation)/segmented/'\n",
    "files = [fn for fn in getFiles(ObjPath, kind='txt') \n",
    "             if 'CSVpointsViewer' not in fn]\n",
    "vnames = []\n",
    "for fn in files:\n",
    "    bp1, name = os.path.split(fn)\n",
    "    bp2, vname = os.path.split(bp1)\n",
    "    vnames.append(vname)\n",
    "    pointData = []\n",
    "    with open(fn + '.txt', 'r') as ofile:\n",
    "        lines = ofile.read().splitlines()\n",
    "    for l in lines:\n",
    "        s = l.split()\n",
    "        if len(s) > 0:\n",
    "            pointData.append(float64(s[:3]))\n",
    "    df = pd.DataFrame(array(pointData), columns=['x', 'y', 'z'])\n",
    "    df.to_csv(fn + '.csv', index=False)\n",
    "vnames = set(vnames)\n",
    "for vname in vnames:\n",
    "    combinedData = []\n",
    "    for fn in files:\n",
    "        base, name = os.path.split(fn)\n",
    "        _, dirname = os.path.split(base)\n",
    "        if not vname == dirname:\n",
    "            continue\n",
    "        if not 'GEMS 1_17' in ObjPath:\n",
    "            segmentNumber = int(name)\n",
    "        else:\n",
    "            segmentNumber = int(name.split('_')[1])\n",
    "        with open(fn + '.txt', 'r') as ofile:\n",
    "            lines = ofile.read().splitlines()\n",
    "        for l in lines:\n",
    "            s = l.split()\n",
    "            if len(s) > 0:\n",
    "                pdata = r_[float64(s[:3]), segmentNumber]\n",
    "                combinedData.append(pdata)\n",
    "    df = pd.DataFrame(array(combinedData), columns=['x', 'y', 'z', 's'])\n",
    "    if savedir == 'GEMS-wbs':\n",
    "        vname = '0' + vname[1:]\n",
    "    df.to_csv(\n",
    "        os.path.join(\n",
    "            ObjPath, \n",
    "            vname + ' (point segments).csv'), \n",
    "        index=False)\n",
    "    df.to_csv(\n",
    "        os.path.join(\n",
    "            savePath, \n",
    "            vname + ' (point segments).csv'), \n",
    "        index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output surfaces as OBJ for manual touchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObjPath = '/Users/jaynewby/Dropbox/Gladfelter/HyphaDensityProject/'\n",
    "ObjPath += savedir + ' (points for segmentation)/surface meshes for touchup/'\n",
    "ObjPath2 = '/Users/jaynewby/Dropbox/Gladfelter/HyphaDensityProject/'\n",
    "ObjPath2 += savedir + ' (points for segmentation)/surface meshes refinished/'\n",
    "files = [fn for fn in getFiles(savePath, kind='dtbin') if 'SurfacesOnly' in fn]\n",
    "if not os.path.isdir(ObjPath):\n",
    "    os.mkdir(ObjPath)\n",
    "if not os.path.isdir(ObjPath2):\n",
    "    os.mkdir(ObjPath2)\n",
    "for fn in files:\n",
    "    _, nameRaw = os.path.split(fn)\n",
    "    name = nameRaw.split('-hyphaeList-SurfacesOnly')[0]\n",
    "    opath = os.path.join(ObjPath, name)\n",
    "    opath2 = os.path.join(ObjPath2, name)\n",
    "    print('---------')\n",
    "    print(opath)\n",
    "    if not os.path.isdir(opath):\n",
    "        os.mkdir(opath)\n",
    "    if not os.path.isdir(opath2):\n",
    "        os.mkdir(opath2)\n",
    "    with DTDataFile(fn + '.dtbin', readonly=True) as sfile:\n",
    "        #print(sfile.variable_names())\n",
    "        #print([k for k in sfile.variable_names() if 'surface_P' in k])\n",
    "        Nsurfs = len([k for k in sfile.variable_names() \n",
    "                          if 'surface_P' in k and not 'bbox' in k])\n",
    "        for n in arange(Nsurfs):\n",
    "            points = sfile['Var_{0}_surface_P'.format(n)][0]\n",
    "            triangles = sfile['Var_{0}_surface'.format(n)][0]\n",
    "            with open(os.path.join(opath, '{0}.obj'.format(n+1)), 'w+b') as ofile:\n",
    "                ofile.write(Make_obj()(points, faces=triangles))\n",
    "            ## save a coppy in the refinished folder if there is no file in there already\n",
    "            ropath = os.path.join(opath2, '{0}.obj'.format(n+1))\n",
    "            if not os.path.exists(ropath):\n",
    "                with open(ropath, 'w+b') as ofile:\n",
    "                    ofile.write(Make_obj()(points, faces=triangles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import new surface meshes into DataTank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObjPath = '/Users/jaynewby/Dropbox/Gladfelter/HyphaDensityProject/'\n",
    "ObjPath += savedir + ' (points for segmentation)/surface meshes refinished/'\n",
    "files = [fn for fn in getFiles(savePath, kind='dtbin') if 'SurfacesOnly' in fn]\n",
    "for fn in files:\n",
    "    bp, nameRaw = os.path.split(fn)\n",
    "    name = nameRaw.split('-hyphaeList-SurfacesOnly')[0]\n",
    "    opath = os.path.join(ObjPath, name)\n",
    "    with DTDataFile(fn + '.dtbin', readonly=True) as sfile:\n",
    "        Nsurfs = len([k for k in sfile.variable_names() \n",
    "                          if 'surface_P' in k and not 'bbox' in k])\n",
    "    with DTDataFile(\n",
    "            os.path.join(\n",
    "                bp, \n",
    "                name + '-newSurfaces.dtbin'), \n",
    "            truncate=True) as sfile:\n",
    "        S = DTSeriesGroup(sfile, 'Var', {'points': 'Array', 'triangles': 'Array'})\n",
    "        for n in arange(Nsurfs):\n",
    "            points, triangles = [], []\n",
    "            with open(os.path.join(opath, '{0}.obj'.format(n+1)), 'r') as ofile:\n",
    "                lines = ofile.read().splitlines()\n",
    "            for l in lines:\n",
    "                s = l.split()\n",
    "                if len(s) > 0 and s[0] == 'v':\n",
    "                    points.append(float64(s[1:4]))\n",
    "                if len(s) > 0 and s[0] == 'f':\n",
    "                    tris = [tri.split('/')[0] for tri in s[1:]]\n",
    "                    triangles.append(int32(tris) - 1)\n",
    "            S.add(\n",
    "                float(n), \n",
    "                {'points': array(points), \n",
    "                 'triangles': array(triangles)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the nuclei tracking json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Njsonfn = '/Users/jaynewby/Dropbox/Gladfelter/GEMS 1_17/Tue Mar 20 21_38_56 2018--nd2.json'\n",
    "# NjsonData = {}\n",
    "# with open(Njsonfn, 'r') as jfile:\n",
    "#     raw = jfile.read().splitlines()\n",
    "# for l in raw:\n",
    "#     NjsonData.update(json.loads(l))\n",
    "# for key in NjsonData:\n",
    "#     print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 3D tetrahedral mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymesh\n",
    "# # input_mesh = pymesh.generate_icosphere(1.0, [0.0, 0.0, 0.0])\n",
    "# filename = '/Users/jaynewby/Dropbox/Gladfelter/HyphaDensityProject/GEMS 1_17 (points for segmentation)/surface meshes refinished/1016/3.obj'\n",
    "# # filename = 'testMesh2.obj'\n",
    "# input_mesh = pymesh.load_mesh(filename)\n",
    "# tetgen = pymesh.tetgen()\n",
    "# tetgen.points = input_mesh.vertices # Input points.\n",
    "# tetgen.triangles = input_mesh.faces # Input triangles\n",
    "# tetgen.max_tet_volume = inf\n",
    "# tetgen.verbosity = 2\n",
    "# tetgen.run() # Execute tetgen\n",
    "# mesh = tetgen.mesh # Extract output tetrahedral mesh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrack nuclei, filtering for size and using MCMC linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reload(MCMC)\n",
    "def DiffusionLink(trackData, NmaxElements, coastLimit=1, CAcost=7.5, Nsamples=1, reverse=False):\n",
    "    Pnew = 0.5#*ones(trackData.shape, 'float16')\n",
    "    F = MCMC.DiffusionFilter(Nsamples, NmaxElements, trackData, Pnew, \n",
    "                               pars, zscale,\n",
    "                               cutOff=40., coastLimit=coastLimit, CAcost=CAcost)\n",
    "    print('linking')\n",
    "    Data = F.track(reverse)\n",
    "    trackData = TD.TrackingData(shape=vidShape).setData(Data)\n",
    "    trackData._trajectoryStats()\n",
    "    oneF = sum([g.frame.size == 1 for p, g in trackData.Data.groupby('particle')])\n",
    "    print('number of 1-frame tracks:', oneF)\n",
    "    print('')\n",
    "    return trackData\n",
    "jsonfn = os.path.join(savePath, 'nuclei.json')\n",
    "with open(jsonfn, 'r') as jfile:\n",
    "    for line in jfile:\n",
    "        data = json.loads(line)\n",
    "        key = data.keys()[0]\n",
    "        vdata = data[key]\n",
    "\n",
    "        _, nameWithExt = os.path.split(key)\n",
    "        name, ext = os.path.splitext(nameWithExt)\n",
    "        print('--------------------')\n",
    "        print(name)\n",
    "        print('--------------------')\n",
    "        fn = os.path.join(savePath, name)\n",
    "        vidMD = loadmat(fn + '-videoMetaData.mat')\n",
    "        vidShape = (int(vidMD['NF'].squeeze()), \n",
    "                    int(vidMD['Ny'].squeeze()/2), \n",
    "                    int(vidMD['Nx'].squeeze()/2), \n",
    "                    int(vidMD['Nz'].squeeze()))\n",
    "        if vidShape[0] <= 50:\n",
    "            continue\n",
    "        zscale = (vidMD['dz']/(2.*vidMD['dxy'])).squeeze()\n",
    "        pdata = vdata['particleSet']\n",
    "        x, y, z, t, p, r = pdata['x'], pdata['y'], pdata['z'], pdata['t'], pdata['p'], pdata['r']\n",
    "        data = array([x, y, z, t, p, r])[:, array(r) > 4.]\n",
    "        df = pd.DataFrame(data.T, columns=['x', 'y', 'z', 't', 'p', 'r'])\\\n",
    "                .astype({'t': 'uint16'})\n",
    "        print('shape:', vidShape)\n",
    "        trackData = TD.TrackingData(shape=vidShape, zscale=zscale)\n",
    "        trackData.particleSet = df\n",
    "        trackData.particleSetGrouped = trackData._makePSgrouped()\n",
    "        trackData.linkParticles(D=0.2)\n",
    "        # trackData.DTsave(fn + '-forDT.mat')\n",
    "        trackData.Data.to_csv(fn + ' (nuclei).csv')\n",
    "\n",
    "        D = 0.05\n",
    "        pars = (D,)\n",
    "\n",
    "        NmaxElements = int(3*trackData.Nparticles)\n",
    "        print('----')\n",
    "        C = 10.\n",
    "\n",
    "    #     trackData.filterPathsByLength(5)\n",
    "        CL = [5, 5, 5, 7, 10, 20]\n",
    "        for n in arange(6):\n",
    "            trackDataHS = DiffusionLink(trackData, NmaxElements, coastLimit=CL[n], CAcost=C, Nsamples=2)\n",
    "            trackDataHS.filterPathsByLength(5)\n",
    "            NmaxElements = int(4*trackDataHS.Nparticles)\n",
    "            C *= 1.2\n",
    "        trackDataHS.filterPathsByLength(50)\n",
    "        trackDataHS._trajectoryStats()\n",
    "        trackDataHS.Data.to_csv(fn + ' (MCMC)(nuclei).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move axial density data to Grace's working folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [fn for fn in getFiles(savePath, kind='dtbin') if 'hyphaAxisDensity' in fn]\n",
    "ObjPath = '/Users/jaynewby/Dropbox/Gladfelter/HyphaDensityProject/'\n",
    "ObjPath += savedir + ' (axialDensityData)/x10t10'\n",
    "if not os.path.isdir(ObjPath):\n",
    "    os.makedirs(ObjPath)\n",
    "for fn in files:\n",
    "    _, name = os.path.split(fn)\n",
    "    outFile = os.path.join(ObjPath, name + '.dtbin')\n",
    "    with open(fn + '.dtbin', 'rb') as afile, open(outFile, 'w+b') as sfile:\n",
    "        sfile.write(afile.read())\n",
    "        \n",
    "# glob = os.path.join(savePath, '*hyphaAxisDensity.dtbin')\n",
    "# !cp {glob} {ObjPath}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TIF max projection files from Beam output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [fn for fn in getFiles(savePath, kind='txt') if 'maxProjectionData' in fn]\n",
    "def procFn(pfile):\n",
    "    data = ''\n",
    "    name = pfile.readline()\n",
    "    assert name[:5] == 'gs://'\n",
    "    while True:\n",
    "        d = pfile.readline()\n",
    "        if len(d) == 0:\n",
    "            yield name, data\n",
    "            break\n",
    "        elif d[:5] == 'gs://':\n",
    "            yield name, data\n",
    "            name = d\n",
    "            data = ''\n",
    "        else:\n",
    "            data += d\n",
    "    \n",
    "for fn in files[1:]:\n",
    "    data = ''\n",
    "    with open(fn+'.txt', 'rb') as pfile:\n",
    "        for nm, data in procFn(pfile):\n",
    "            _, name = os.path.split(nm[:-1])\n",
    "            with open(os.path.join(savePath, name+'.tif'), 'w+b') as sfile:\n",
    "                sfile.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract pixel size and framerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [fn for fn in getFiles(savePath, kind='mat') if 'videoMetaData' in fn]\n",
    "DT = {}\n",
    "DXY = {}\n",
    "for fn in files:\n",
    "    md = loadmat(fn+'.mat')\n",
    "    _, name = os.path.split(fn)\n",
    "    name = name.replace('-videoMetaData', '')\n",
    "    DT[name] = 1.*md['dt'].squeeze()\n",
    "    DXY[name] = 1.*md['dxy'].squeeze()\n",
    "print(DT)\n",
    "print('------')\n",
    "print(DXY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total size of video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from apache_beam.io.filesystems import FileSystems\n",
    "match_result = FileSystems.match(\n",
    "    [os.path.join('gs://gems-drive/GEMS/', '**.nd2')])[0]\n",
    "files_metadata = match_result.metadata_list\n",
    "total_size = 0\n",
    "for md in files_metadata:\n",
    "    total_size += md.size_in_bytes\n",
    "print(total_size/1e12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## colorbar figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmapfile = '/Users/jaynewby/Dropbox/DataTankCode/more_cmaps/rainbow_bgyr_35-85_c73_n256.csv'\n",
    "cdf = pd.read_csv(cmapfile, names=['x', 'y', 'z'])\n",
    "cm0 = matplotlib.pylab.get_cmap('jet')\n",
    "cm = cm0.from_list('rbow', float64(array(cdf))/255.)\n",
    "matplotlib.style.use('dark_background')\n",
    "scale = array([1e-4, 1e-3, 1e-2, 1e-1])\n",
    "labels = [r'$10^{-4}$',r'$10^{-3}$',r'$10^{-2}$',r'$10^{-1}$']\n",
    "X, Y = meshgrid(linspace(0, 1.05), linspace(0, 1.05))\n",
    "figure(1, [1, 10])\n",
    "pcolor(X, Y, Y, cmap=cm)\n",
    "xticks([])\n",
    "yticks([0, 0.33, 0.66, 1], labels, fontsize=24)\n",
    "title(r'$\\mu \\rm{m}^2/\\rm{sec}$', fontsize=24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
